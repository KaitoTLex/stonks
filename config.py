# config.py

CUSTOM_STOCK_LIST = [
    "F",
    "BAC",
    "PFE",
    "MO",
    "TSN",
    "HRL",
    "BP",
    "BASFY",
    "KLIC",
    "HFC",
    "BF.B",
    "SLB",
    "GE",
    "KO",
    "PEP",
    "WMT",
    "CVS",
    "KHC",
    "VZ",
    "T",
    "ABBV",
    "NEE",
    "DUK",
    "SO",
    "AEP",
    "XEL",
    "ETR",
    "DTE",
    "CMS",
    "FE",
    "ED",
    "EXC",
    "PPL",
    "SRE",
    "PCG",
    "WEC",
    "NRG",
    "DCP",
    "OKE",
    "KMI",
    "EPD",
    "MPLX",
    "TRP",
    "ENB",
    "BNS",
    "TD",
    "CM",
    "RY",
    "BMO",
    "NA",
    "MSFT",
    "AAPL",
    "GOOGL",
    "AMZN",
    "NVDA",
    "TSLA",
    "META",
    "JPM",
    "V",
    "JNJ",
    "WMT",
    "XOM",
    "UNH",
    "PG",
    "MA",
    "HD",
    "CVX",
    "MRK",
    "BAC",
    "PFE",
    "KO",
    "ABBV",
    "COST",
    "TMO",
    "PEP",
    "AVGO",
    "CMCSA",
    "DIS",
    "NFLX",
    "ADBE",
    "CSCO",
    "ACN",
    "CRM",
    "INTC",
    "QCOM",
    "TXN",
    "AMGN",
    "MSI",
    "NEE",
    "UPS",
    "LOW",
    "CVS",
    "IBM",
    "MDT",
    "HON",
    "GE",
    "PLD",
    "SBUX",
    "BKNG",
    "AMD",
]

NUM_STOCKS_PER_EPISODE = 15  # Number of tickers agent trades simultaneously

INITIAL_BALANCE = 10000.0  # Starting cash for agent

# Reward weights
ALPHA_REWARD = 1.0  # portfolio value change weight
BETA_REWARD = 0.5  # sharpe ratio weight
GAMMA_REWARD = 0.2  # per-trade profit weight

# Episode length in hours (approx 3 months)
EPISODE_HOURS = 24 * 90

# Agent training params (keep your previous config or extend as needed)
config = {
    "env": {
        "window_size": 1,  # we only use 1-hour raw data per step here
        "initial_balance": INITIAL_BALANCE,
    },
    "agent": {
        "gamma": 0.99,
        "epsilon": 1.0,
        "epsilon_min": 0.05,
        "epsilon_decay": 0.995,
        "lr": 1e-3,
        "batch_size": 32,
        "memory_size": 10000,
        "target_update_freq": 50,
    },
    "training": {
        "episodes": 200,
        "max_steps": EPISODE_HOURS,
        "save_every": 25,
        "weights_path": "models/dqn_weights.pth",
    },
}
